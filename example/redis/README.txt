修改配置:
redis.conf

启动命令:
./bin/redis-server ./redis.conf

#####################################

Redis集群没有使用一致性hash, 而是引入了哈希槽的概念, Redis集群有16384个哈希槽,
每个key通过CRC16校验后对16384取模来决定放置哪个槽, 集群的每个节点负责一部分hash槽
Redis集群最大节点个数是16384

redis集群数据路由规则
计算公式: slot = CRC16（key）& 16383

#####################################

redis内存淘汰策略
1. volatile-lru: 从设置过期时间的数据集（server.db[i].expires）中挑选出最近最少使用的数据淘汰,
没有设置过期时间的key不会被淘汰, 这样就可以在增加内存空间的同时保证需要持久化的数据不会丢失

2. volatile-ttl: 除了淘汰机制采用LRU, 策略基本上与volatile-lru相似,
从设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰, ttl值越大越优先被淘汰

3. volatile-random: 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰,
当内存达到限制无法写入非过期时间的数据集时, 可以通过该淘汰策略在主键空间中随机移除某个key

4. allkeys-lru: 从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰,
该策略要淘汰的key面向的是全体key集合, 而非过期的key集合

5. allkeys-random: 从数据集(server.db[i].dict）中选择任意数据淘汰

6. no-enviction: 禁止驱逐数据, 也就是当内存不足以容纳新入数据时, 新写入操作就会报错,
请求可以继续进行, 线上任务也不能持续进行, 采用no-enviction策略可以保证数据不被丢失, 这也是系统默认的一种淘汰策略

#####################################

数据类型及应用
zset排序
set去重
string
list
hash

#####################################

redis主从同步的实现过程

1）一个slave实例, 无论是第一次连接还是重连到master, 它都会发出一个SYNC命令

2）当master收到SYNC命令之后, 会做两件事:
(a) master执行BGSAVE，即在后台保存数据到磁盘（rdb快照文件）
(b) master同时将新收到的写入和修改数据集的命令存入缓冲区（非查询类）

3）当master在后台把数据保存到快照文件完成之后, master会把这个快照文件传送给slave,
而slave则把内存清空后，加载该文件到内存中

4）而Master也会把此前收集到缓冲区中的命令, 通过reids命令协议形式转发给slave,
slave执行这些命令, 实现和master的同步

5）master/slave此后会不断通过异步方式进行命令的同步, 达到最终数据的同步一致

#####################################

redis主从切换过程
哨兵: 通过sentinel模式启动redis后, 自动监控master/slave的运行状态, 基本原理是: 心跳机制+投票裁决

cluster: 自动切换
redis cluster功能: 负载均衡、故障切换、主从复制
当一个从节点发现自己正在复制的主节点进入了已下线状态时, 从节点将开始对下线主节点进行故障转移, 以下是故障转移执行的步骤:
从节点会执行SLAVEOF no one命令, 成为新的主节点,
新的主节点会撤销所有对已下线主节点的槽指派, 并将这些槽全部指派给自己,
新的主节点向集群广播一条PONG消息, 这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点,
并且这个主节点已经接管了原本由已下线节点负责处理的槽
新的主节点开始接收和自己负责处理的槽有关的命令请求, 故障转移完成

#####################################

集群机器之间的通信
meet消息: 用于通知新节点加入, 消息发送者通知接收者加入到当前集群, meet消息通信正常完成后,
接收节点会加入到集群中并进行周期性的ping、pong消息交换

ping消息: 集群内交换最频繁的消息, 集群内每个节点每秒向多个其他节点发送ping消息,
用于检测节点是否在线和交换彼此状态信息, ping消息发送封装了自身节点和部分其他节点的状态数据

pong消息: 当接收到ping、meet消息时, 作为响应消息回复给发送方确认消息正常通信,
pong消息内部封装了自身状态数据, 节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新

fail消息: 当节点判定集群内另一个节点下线时, 会向集群内广播一个fail消息,
其他节点接收到fail消息之后把对应节点更新为下线状态

#####################################

redis为什么快:
1. 纯内存操作, 避免大量访问数据库, 减少直接读取磁盘数据, redis将数据储存在内存里面,
读写数据的时候都不会受到硬盘 I/O 速度的限制, 所以速度快

2. 单线程操作, 避免了不必要的上下文切换和竞争条件, 也不存在多进程或者多线程导致的切换而消耗CPU,
不用去考虑各种锁的问题, 不存在加锁释放锁操作, 没有因为可能出现死锁而导致的性能消耗

3. 采用了非阻塞I/O多路复用机制

4. 灵活多样的数据结构, redis内部使用一个redisObject对象来表示所有的key和value.
redisObject主要的信息包括数据类型、编码方式、数据指针、虚拟内存等.
它包含String、Hash、List、Set、SortedSet五种数据类型, 针对不同的场景使用对应的数据类型,
减少内存使用的同时, 节省网络流量传输

单线程还快的原因:
读取数据是通过IO多路复用实现, 而在底层, 是通过epoll实现,
epoll相比于select(不是Java NIO的select, 是Linux的select)主要有以下两个优点:
一、提高了遍历socket的效率, 即时有上百万个连接, 它也只会遍历有事件的连接,
而select需要全部遍历一遍
二、是通过mmap实现了内核态与用户态的共享内存, 也就是数据从网卡到达复制到内核空间,
不需要复制到用户空间了, 所以使用epoll, 如果发现有读事件, 那么内存里的数据也准备好了, 不需要拷贝
通过以上可以得出, 读取数据是十分快的

接下来就是处理数据, 这才是能使用单线程的本质原因.
redis的业务逻辑是纯内存操作, 耗时是纳秒级的, 所以事件可以忽略不计.
假如我们是一个复杂的web应用, 业务逻辑涉及到读数据库, 调用其它模块, 那么是不能用单线程的
同样, 写数据也是通过epoll共享内存, 只要把结果计算后放到用户内存, 然后通知操作系统就可以了

所以, redis能单线程支撑上万tps的前提就是每个请求都是内存操作,
事件都特别短, 但凡有一次请求慢了, 就会导致请求阻塞.
假设99.99%的请求响应时间都在1ms以内, 而0.01%的请求时间为1s,
那么单线程模型在处理1s请求的时候, 剩余1ms的请求也都得排队

#####################################

redis实现分布式锁:
1.加锁setnx(key, 1)
2.解锁del(key)
3.锁超时setnx(key, 1) == 1 && expire(key, 30)

致命问题:
1. setnx和expire的非原子性
setnx指令本身是不支持传入超时时间的, Redis 2.6.12以上版本为set指令增加了可选参数,
伪代码如下: set(key, 1, 30, NX), 这样就可以取代setnx指令

2. 超时后使用del 导致误删其他线程的锁
假如某线程成功得到了锁, 并且设置的超时时间是30秒.
如果某些原因导致线程A执行的很慢很慢, 过了30秒都没执行完, 这时候锁过期自动释放, 线程B得到了锁.
随后, 线程A执行完了任务, 线程A接着执行del指令来释放锁. 但这时候线程B还没执行完, 线程A实际上删除的是线程B加的锁.
怎么避免这种情况呢?可以在del释放锁之前做一个判断, 验证当前的锁是不是自己加的锁.
至于具体的实现, 可以在加锁的时候获取一个UUID当做value, 并在删除之前验证key对应的value是不是自己的UUID.
这样, 解锁if判断和释放锁是两个独立操作, 不是原子性, 所以这一块要用Lua脚本来实现:
String luaScript = 'if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end';
redisClient.eval(luaScript , Collections.singletonList(key), Collections.singletonList(threadId));
这样一来, 验证和删除过程就是原子操作了.

3. 出现并发的可能性(锁续命)
还是刚才第二点所描述的场景, 虽然我们避免了线程A误删掉key的情况,
但是同一时间有A、B两个线程在访问代码块, 仍然是不完美的.
怎么办呢?我们可以让获得锁的线程开启一个守护线程, 用来给快要过期的锁"续航".
当过去了29秒, 线程A还没执行完, 这时候守护线程会执行expire指令, 为这把锁"续命"20秒.
守护线程从第29秒开始执行, 每20秒执行一次.
当线程A执行完任务, 会显式关掉守护线程.
另一种情况, 如果节点1忽然断电, 由于线程A和守护线程在同一个进程, 守护线程也会停下.
这把锁到了超时的时候, 没人给它续命, 也就自动释放了.

#####################################

redis数据结构:
list:
quickList就是一个标准的双向链表的配置, 有head 有tail
每一个节点是一个quicklistNode, 包含prev和next指针
每一个quicklistNode 包含 一个ziplist, *zp 压缩链表里存储键值
所以quicklist是对ziplist进行一次封装, 使用小块的ziplist来既保证了少使用内存, 也保证了性能
在redis.conf配置文件中, 有两个参数可以优化列表:
list-max-ziplist-size: 表示每个quicklistNode的字节大小, 默认为-2 表示8KB
list-compress-depth: 表示quicklistNode节点是否要压缩, 默认是0 表示不压缩

string:
free属性的值为0, 表示这个SDS没有任何剩余的可使用字节数
len为5, 表示这个SDS保存了一个长度为5的字符串
buf属性是一个char类型的数组, 数组的前五个字节分别保存了'R'、'e'、'd'、'i'、's'五个字符,
而最后一个字节则保存空字符'\0', 代表字符串结束


什么是跳表:
一般跳跃表的实现, 主要包含以下几个部分:
表头（head）: 指向头节点
表尾（tail）: 指向尾节点
节点（node）: 实际保存的元素节点, 每个节点可以有多层, 层数是在创建此节点的时候随机生成的一个数值, 而且每一层都是一个指向后面某个节点的指针.
层（level）: 目前表内节点的最大层数
长度（length）: 节点的数量
对于一个单链表来讲, 即便链表中存储的数据是有序的, 如果我们要想在其中查找某个数据, 也只能从头到尾遍历链表.
这样查找效率就会很低, 时间复杂度会很高, 是 O(n).
如果我们想要提高其查找效率, 可以考虑在链表上建索引的方式. 每两个结点提取一个结点到上一级, 我们把抽出来的那一级叫作索引.
这个时候, 我们假设要查找节点8, 我们可以先在索引层遍历, 当遍历到索引层中值为 7 的结点时, 发现下一个节点是9,
那么要查找的节点8肯定就在这两个节点之间. 我们下降到链表层继续遍历就找到了8这个节点.
原先我们在单链表中找到8这个节点要遍历8个节点, 而现在有了一级索引后只需要遍历五个节点.
从这个例子里, 我们看出, 加来一层索引之后, 查找一个结点需要遍的结点个数减少了, 也就是说查找效率提高了, 同理再加一级索引,
查找效率又有提升. 在例子中我们的数据很少, 当有大量的数据时, 我们可以增加多级索引, 其查找效率可以得到明显提升.

zset:
zset为有序（有限score排序, score相同则元素字典序）,自动去重的集合数据类型,
其底层实现为 字典（dict） + 跳表（skiplist）, 当数据比较少的时候用ziplist编码结构存储
header: 指向跳跃表的表头节点, 通过这个指针程序定位表头节点的时间复杂度就为O(1)
tail: 指向跳跃表的表尾节点, 通过这个指针程序定位表尾节点的时间复杂度就为O(1)
level: 记录目前跳跃表内, 层数最大的那个节点的层数(表头节点的层数不计算在内),
通过这个属性可以再O(1)的时间复杂度内获取层高最好的节点的层数
length: 记录跳跃表的长度, 也即是, 跳跃表目前包含节点的数量(表头节点不计算在内),
通过这个属性, 程序可以再O(1)的时间复杂度内返回跳跃表的长度.

哈希(hash)
redis的散列可以存储多个键值对之间的映射, 散列存储的值既可以是字符串又可以是数字值,
并且用户同样可以对散列存储的数字值执行自增操作或者自减操作. 散列可以看作是一个文档或关系数据库里的一行,
hash底层的数据结构实现有两种:
一种是ziplist, 上面已经提到过.
当存储的数据超过配置的阀值时就是转用hashtable的结构, 这种转换比较消耗性能, 所以应该尽量避免这种转换操作.
同时满足以下两个条件时才会使用这种结构:
当键的个数小于hash-max-ziplist-entries（默认512）
当所有值都小于hash-max-ziplist-value（默认64）
另一种就是hashtable. 这种结构的时间复杂度为O(1), 但是会消耗比较多的内存空间.

#####################################

AOF rewrite原理:
redis中的数据是有限的, 很多数据可能会自动过期, 可能会被用户删除, 也有可能被redis用缓存清除的算法清理掉
redis中的数据会不断淘汰掉旧的数据, 只有一部分常用的数据会自动保留在redis内存中
所以很可能之前已经被清理掉的数据, 对应的写日志还停留在AOF中, AOF日志文件就一个, 会不断的膨胀

所以基于上面的原因, AOF会自动在后台每隔一定时间做rewrite操作,
比如日志里已经存放了针对100w数据的写日志, 而redis内存中此时只有10w数据,
rewrite会基于当前内存中10w数据构建一套最新的日志到AOF中, 覆盖之前的老日志

在redis.conf中, 可以配置rewrite的策略:
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
大小超过64mb, 且比上次增长了100%才会触发一次rewrite

具体rewrite步骤:
redis fork一个子进程
子进程基于当前内存中的数据, 构建日志, 开始往一个新的临时AOF文件中写入日志
redis主进程, 接收到client新的写操作之后, 在内存中写入日志, 同时新的日志也继续写入旧的AOF文件
用新的日志文件替换掉旧的日志文件

AOF破损文件的修复:
如果redis在append数据到AOF文件时, 机器宕机了, 可能会导致AOF文件破损
用redis-check-aof --fix命令来修复破损的AOF文件

重写原理
AOF文件持续增长而过大时, 会fork出一条新进程来将文件重写(也是先写临时文件最后再rename), 遍历新进程的内存中数据,
每条记录有一条的Set语句. 重写aof文件的操作, 并没有读取旧的aof文件,
而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件, 这点和快照有点类似.

#####################################

redis集群环境把类似得key放到同一个节点上:
要想在hash槽集群环境下批量操作多个key,
只有这些key处在同一个节点下才会生效并且只要在key得前面加上一个相同得部分,
并用花括号括起来然后和后面正在得key间隔一个字符即可, 则前面得这个花括号部分为hash tags,
顾名思义就是用来计算hash落点得部分, 有效key为间隔一个字符之后得key.
"{node1} key1"

#####################################

布隆过滤器(Bloom Filter)
直观的说, bloom算法类似一个hash set, 用来判断某个元素（key）是否在某个集合中.
和一般的hash set不同的是, 这个算法无需存储key的值, 对于每个key, 只需要k个比特位, 每个存储一个标志, 用来判断key是否在集合中.

算法:
1. 首先需要k个hash函数, 每个函数可以把key散列成为1个整数.
2. 初始化时, 需要一个长度为n比特的数组, 每个比特位初始化为0.
3. 某个key加入集合时, 用k个hash函数计算出k个散列值, 并把数组中对应的比特位置为1.
4. 判断某个key是否在集合时, 用k个hash函数计算出k个散列值, 并查询数组中对应的比特位, 如果所有的比特位都是1, 认为在集合中.

优点: 不需要存储key, 节省空间

缺点:
1. 算法判断key在集合中时, 有一定的概率key其实不在集合中
2. 无法删除

#####################################

延迟队列的需求各位应该在日常开发的场景中经常碰到:
一般这种场景和定时任务还是有很大的区别, 定时任务是你知道任务多久该跑一次或者什么时候只跑一次, 这个时间是确定的.
延迟队列是当某个事件发生的时候需要延迟多久触发配套事件, 引子事件发生的时间不是固定的.

1. 用户登录之后5分钟给用户做分类推送
2. 用户多少天未登录给用户做召回推送
3. 定期检查用户当前退款账单是否被商家处理等等场景

1. Redis zset
这个方案比较常用, 简单有效. 利用 Redis 的 sorted set 结构, 使用 timeStamp 作为 score,
比如你的任务是要延迟5分钟, 那么就在当前时间上加5分钟作为 score , 轮询任务每秒只轮询 score 大于当前时间的 key即可,
如果任务支持有误差, 那么当没有扫描到有效数据的时候可以休眠对应时间再继续轮询.
缺点:
单个 zset 肯定支持不了太大的数据量, 如果你有几百万的延迟任务需求, 大哥我还是劝你换一个方案.
定时器轮询方案可能会有异常终止的情况需要自己处理, 同时消息处理失败的回滚方案, 您也要自己处理.

#####################################

缓存穿透
描述:
缓存穿透是指缓存和数据库中都没有的数据, 而用户不断发起请求, 由于缓存是不命中时被动写的,
并且出于容错考虑, 如果从存储层查不到数据则不写入缓存, 这将导致这个不存在的数据每次请求都要到存储层去查询, 失去了缓存的意义
解决方案:
接口层增加校验, 如用户鉴权校验, id做基础校验, id<=0的直接拦截.


缓存击穿
描述:
缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期）, 这时由于并发用户特别多, 同时读缓存没读到数据,
又同时去数据库去取数据, 引起数据库压力瞬间增大, 造成过大压力.
解决方案:
1、设置热点数据永远不过期
2、接口限流与熔断, 降级
3、布隆过滤器
4、加互斥锁

缓存雪崩
描述:
缓存雪崩是指缓存中数据大批量到过期时间, 而查询数据量巨大, 引起数据库压力过大甚至down机.
和缓存击穿不同的是, 缓存击穿指并发查同一条数据, 缓存雪崩是不同数据都过期了, 很多数据都查不到从而查数据库
解决方案:
缓存数据的过期时间设置随机, 防止同一时间大量数据过期现象发生.
如果缓存数据库是分布式部署, 将热点数据均匀分布在不同搞得缓存数据库中.
设置热点数据永远不过期.